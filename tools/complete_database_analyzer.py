#!/usr/bin/env python3
"""
CoreBank æ•°æ®åº“ç»“æ„å®Œæ•´æå–å·¥å…·
æå–æ•°æ®åº“çš„å®Œæ•´ç»“æ„ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¡¨ã€åˆ—ã€ç´¢å¼•ã€çº¦æŸã€å…³ç³»ç­‰
"""

import subprocess
import json
import sys
import os
from datetime import datetime
from typing import Dict, List, Any, Optional

class DatabaseStructureAnalyzer:
    """æ•°æ®åº“ç»“æ„åˆ†æå™¨"""
    
    def __init__(self, container_name="corebank_postgres", db_user="corebank_user", db_name="corebank"):
        self.container_name = container_name
        self.db_user = db_user
        self.db_name = db_name
        self.structure_data = {}
    
    def execute_sql(self, query: str) -> str:
        """æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶è¿”å›ç»“æœ"""
        cmd = [
            "podman", "exec", self.container_name,
            "psql", "-U", self.db_user, "-d", self.db_name,
            "-c", query
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            print(f"âŒ SQLæ‰§è¡Œé”™è¯¯: {e}")
            return ""
    
    def get_database_info(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“åŸºæœ¬ä¿¡æ¯"""
        print("ğŸ“Š è·å–æ•°æ®åº“åŸºæœ¬ä¿¡æ¯...")
        
        # æ•°æ®åº“ç‰ˆæœ¬
        version_result = self.execute_sql("SELECT version();")
        
        # æ•°æ®åº“å¤§å°
        size_result = self.execute_sql(f"SELECT pg_size_pretty(pg_database_size('{self.db_name}'));")
        
        # è¡¨æ•°é‡
        table_count = self.execute_sql("""
        SELECT COUNT(*) 
        FROM information_schema.tables 
        WHERE table_schema = 'public' AND table_type = 'BASE TABLE';
        """)
        
        return {
            "database_name": self.db_name,
            "version": self._extract_value(version_result),
            "size": self._extract_value(size_result),
            "table_count": self._extract_value(table_count),
            "analysis_time": datetime.now().isoformat()
        }
    
    def _extract_value(self, result: str) -> str:
        """ä»æŸ¥è¯¢ç»“æœä¸­æå–å€¼"""
        lines = result.split('\n')
        for line in lines:
            line = line.strip()
            if line and not line.startswith('-') and not line.startswith('(') and not 'row' in line and not line.startswith('version') and not line.startswith('pg_size_pretty') and not line.startswith('count'):
                return line
        return ""
    
    def get_all_tables(self) -> List[str]:
        """è·å–æ‰€æœ‰è¡¨å"""
        print("ğŸ“‹ è·å–æ‰€æœ‰è¡¨å...")
        
        query = """
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_type = 'BASE TABLE'
        ORDER BY table_name;
        """
        
        result = self.execute_sql(query)
        tables = []
        
        for line in result.split('\n'):
            line = line.strip()
            if line and not line.startswith('-') and not line.startswith('table_name') and not line.endswith('rows)'):
                if line and not line.startswith('('):
                    tables.append(line)
        
        return tables
    
    def get_table_structure(self, table_name: str) -> Dict[str, Any]:
        """è·å–è¡¨çš„å®Œæ•´ç»“æ„ä¿¡æ¯"""
        print(f"ğŸ” åˆ†æè¡¨: {table_name}")
        
        structure = {
            "table_name": table_name,
            "columns": self.get_table_columns(table_name),
            "constraints": self.get_table_constraints(table_name),
            "indexes": self.get_table_indexes(table_name),
            "foreign_keys": self.get_table_foreign_keys(table_name),
            "row_count": self.get_table_row_count(table_name),
            "table_size": self.get_table_size(table_name)
        }
        
        return structure
    
    def get_table_columns(self, table_name: str) -> List[Dict[str, Any]]:
        """è·å–è¡¨åˆ—ä¿¡æ¯"""
        query = f"""
        SELECT 
            column_name,
            data_type,
            is_nullable,
            column_default,
            character_maximum_length,
            numeric_precision,
            numeric_scale,
            ordinal_position
        FROM information_schema.columns 
        WHERE table_name = '{table_name}' 
        ORDER BY ordinal_position;
        """
        
        result = self.execute_sql(query)
        columns = []
        
        lines = result.split('\n')
        data_started = False
        
        for line in lines:
            line = line.strip()
            if '|' in line and data_started:
                parts = [p.strip() for p in line.split('|')]
                if len(parts) >= 8:
                    columns.append({
                        "name": parts[0],
                        "data_type": parts[1],
                        "nullable": parts[2] == "YES",
                        "default": parts[3] if parts[3] and parts[3] != '' else None,
                        "max_length": parts[4] if parts[4] and parts[4] != '' else None,
                        "precision": parts[5] if parts[5] and parts[5] != '' else None,
                        "scale": parts[6] if parts[6] and parts[6] != '' else None,
                        "position": int(parts[7]) if parts[7].isdigit() else 0
                    })
            elif line.startswith('column_name'):
                data_started = True
        
        return columns
    
    def get_table_constraints(self, table_name: str) -> List[Dict[str, Any]]:
        """è·å–è¡¨çº¦æŸä¿¡æ¯"""
        query = f"""
        SELECT 
            tc.constraint_name,
            tc.constraint_type,
            kcu.column_name
        FROM information_schema.table_constraints tc
        LEFT JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
        WHERE tc.table_name = '{table_name}'
        ORDER BY tc.constraint_type, tc.constraint_name;
        """
        
        result = self.execute_sql(query)
        constraints = []
        
        lines = result.split('\n')
        data_started = False
        
        for line in lines:
            line = line.strip()
            if '|' in line and data_started:
                parts = [p.strip() for p in line.split('|')]
                if len(parts) >= 3:
                    constraints.append({
                        "name": parts[0],
                        "type": parts[1],
                        "column": parts[2] if parts[2] and parts[2] != '' else None
                    })
            elif 'constraint_name' in line:
                data_started = True
        
        return constraints
    
    def get_table_indexes(self, table_name: str) -> List[Dict[str, Any]]:
        """è·å–è¡¨ç´¢å¼•ä¿¡æ¯"""
        query = f"""
        SELECT 
            indexname,
            indexdef
        FROM pg_indexes 
        WHERE tablename = '{table_name}'
        ORDER BY indexname;
        """
        
        result = self.execute_sql(query)
        indexes = []
        
        lines = result.split('\n')
        data_started = False
        
        for line in lines:
            line = line.strip()
            if '|' in line and data_started:
                parts = [p.strip() for p in line.split('|')]
                if len(parts) >= 2:
                    indexes.append({
                        "name": parts[0],
                        "definition": parts[1]
                    })
            elif 'indexname' in line:
                data_started = True
        
        return indexes
    
    def get_table_foreign_keys(self, table_name: str) -> List[Dict[str, Any]]:
        """è·å–è¡¨å¤–é”®ä¿¡æ¯"""
        query = f"""
        SELECT 
            tc.constraint_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name
        FROM information_schema.table_constraints AS tc
        JOIN information_schema.key_column_usage AS kcu
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage AS ccu
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY' 
        AND tc.table_name = '{table_name}'
        ORDER BY kcu.column_name;
        """
        
        result = self.execute_sql(query)
        foreign_keys = []
        
        lines = result.split('\n')
        data_started = False
        
        for line in lines:
            line = line.strip()
            if '|' in line and data_started:
                parts = [p.strip() for p in line.split('|')]
                if len(parts) >= 4:
                    foreign_keys.append({
                        "constraint_name": parts[0],
                        "column": parts[1],
                        "referenced_table": parts[2],
                        "referenced_column": parts[3]
                    })
            elif 'constraint_name' in line:
                data_started = True
        
        return foreign_keys
    
    def get_table_row_count(self, table_name: str) -> int:
        """è·å–è¡¨è¡Œæ•°"""
        query = f"SELECT COUNT(*) FROM {table_name};"
        result = self.execute_sql(query)
        
        for line in result.split('\n'):
            line = line.strip()
            if line.isdigit():
                return int(line)
        
        return 0
    
    def get_table_size(self, table_name: str) -> str:
        """è·å–è¡¨å¤§å°"""
        query = f"SELECT pg_size_pretty(pg_total_relation_size('{table_name}'));"
        result = self.execute_sql(query)
        return self._extract_value(result)

    def get_all_foreign_key_relationships(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å¤–é”®å…³ç³»"""
        print("ğŸ”— åˆ†æå¤–é”®å…³ç³»...")

        query = """
        SELECT
            tc.table_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name,
            tc.constraint_name
        FROM information_schema.table_constraints AS tc
        JOIN information_schema.key_column_usage AS kcu
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage AS ccu
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY'
        ORDER BY tc.table_name, kcu.column_name;
        """

        result = self.execute_sql(query)
        relationships = []

        lines = result.split('\n')
        data_started = False

        for line in lines:
            line = line.strip()
            if '|' in line and data_started:
                parts = [p.strip() for p in line.split('|')]
                if len(parts) >= 5:
                    relationships.append({
                        "from_table": parts[0],
                        "from_column": parts[1],
                        "to_table": parts[2],
                        "to_column": parts[3],
                        "constraint_name": parts[4]
                    })
            elif 'table_name' in line:
                data_started = True

        return relationships

    def get_database_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“ˆ è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯...")

        tables = self.get_all_tables()
        total_rows = 0
        table_stats = []

        for table in tables:
            row_count = self.get_table_row_count(table)
            table_size = self.get_table_size(table)
            total_rows += row_count

            table_stats.append({
                "table_name": table,
                "row_count": row_count,
                "size": table_size
            })

        return {
            "total_tables": len(tables),
            "total_rows": total_rows,
            "table_statistics": table_stats
        }

    def analyze_complete_structure(self) -> Dict[str, Any]:
        """å®Œæ•´åˆ†ææ•°æ®åº“ç»“æ„"""
        print("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®åº“ç»“æ„åˆ†æ...")
        print("=" * 60)

        # è·å–åŸºæœ¬ä¿¡æ¯
        db_info = self.get_database_info()
        print(f"æ•°æ®åº“: {db_info['database_name']}")
        print(f"ç‰ˆæœ¬: {db_info['version']}")
        print(f"å¤§å°: {db_info['size']}")

        # è·å–æ‰€æœ‰è¡¨
        tables = self.get_all_tables()
        print(f"è¡¨æ•°é‡: {len(tables)}")

        # åˆ†ææ¯ä¸ªè¡¨
        table_structures = []
        for table in tables:
            structure = self.get_table_structure(table)
            table_structures.append(structure)

        # è·å–å¤–é”®å…³ç³»
        foreign_key_relationships = self.get_all_foreign_key_relationships()

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        statistics = self.get_database_statistics()

        # ç»„è£…å®Œæ•´ç»“æ„
        complete_structure = {
            "database_info": db_info,
            "tables": table_structures,
            "foreign_key_relationships": foreign_key_relationships,
            "statistics": statistics
        }

        return complete_structure

    def save_structure_to_file(self, structure: Dict[str, Any], filename: Optional[str] = None) -> str:
        """ä¿å­˜ç»“æ„åˆ°JSONæ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"database_structure_{timestamp}.json"

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(structure, f, ensure_ascii=False, indent=2, default=str)

        print(f"âœ… æ•°æ®åº“ç»“æ„å·²ä¿å­˜åˆ°: {filename}")
        return filename

    def generate_markdown_report(self, structure: Dict[str, Any], filename: Optional[str] = None) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"database_analysis_report_{timestamp}.md"

        with open(filename, 'w', encoding='utf-8') as f:
            f.write("# CoreBank æ•°æ®åº“ç»“æ„åˆ†ææŠ¥å‘Š\n\n")

            # åŸºæœ¬ä¿¡æ¯
            db_info = structure['database_info']
            f.write("## ğŸ“Š æ•°æ®åº“åŸºæœ¬ä¿¡æ¯\n\n")
            f.write(f"- **æ•°æ®åº“å**: {db_info['database_name']}\n")
            f.write(f"- **ç‰ˆæœ¬**: {db_info['version']}\n")
            f.write(f"- **å¤§å°**: {db_info['size']}\n")
            f.write(f"- **è¡¨æ•°é‡**: {db_info['table_count']}\n")
            f.write(f"- **åˆ†ææ—¶é—´**: {db_info['analysis_time']}\n\n")

            # ç»Ÿè®¡ä¿¡æ¯
            stats = structure['statistics']
            f.write("## ğŸ“ˆ æ•°æ®ç»Ÿè®¡\n\n")
            f.write("| è¡¨å | è¡Œæ•° | å¤§å° |\n")
            f.write("|------|------|------|\n")
            for table_stat in stats['table_statistics']:
                f.write(f"| {table_stat['table_name']} | {table_stat['row_count']} | {table_stat['size']} |\n")
            f.write(f"\n**æ€»è®¡**: {stats['total_tables']} ä¸ªè¡¨ï¼Œ{stats['total_rows']} è¡Œæ•°æ®\n\n")

            # å¤–é”®å…³ç³»
            f.write("## ğŸ”— å¤–é”®å…³ç³»\n\n")
            for rel in structure['foreign_key_relationships']:
                f.write(f"- {rel['from_table']}.{rel['from_column']} â†’ {rel['to_table']}.{rel['to_column']}\n")
            f.write("\n")

            # è¡¨ç»“æ„è¯¦æƒ…
            f.write("## ğŸ—ï¸ è¡¨ç»“æ„è¯¦æƒ…\n\n")
            for table in structure['tables']:
                f.write(f"### {table['table_name']}\n\n")
                f.write(f"**è¡Œæ•°**: {table['row_count']} | **å¤§å°**: {table['table_size']}\n\n")

                # åˆ—ä¿¡æ¯
                f.write("#### åˆ—ä¿¡æ¯\n\n")
                f.write("| åˆ—å | æ•°æ®ç±»å‹ | å¯ç©º | é»˜è®¤å€¼ |\n")
                f.write("|------|----------|------|--------|\n")
                for col in table['columns']:
                    nullable = "æ˜¯" if col['nullable'] else "å¦"
                    default = col['default'] if col['default'] else "-"
                    f.write(f"| {col['name']} | {col['data_type']} | {nullable} | {default} |\n")
                f.write("\n")

                # çº¦æŸä¿¡æ¯
                if table['constraints']:
                    f.write("#### çº¦æŸ\n\n")
                    for constraint in table['constraints']:
                        f.write(f"- **{constraint['name']}** ({constraint['type']})")
                        if constraint['column']:
                            f.write(f": {constraint['column']}")
                        f.write("\n")
                    f.write("\n")

                # ç´¢å¼•ä¿¡æ¯
                if table['indexes']:
                    f.write("#### ç´¢å¼•\n\n")
                    for index in table['indexes']:
                        f.write(f"- **{index['name']}**\n")
                    f.write("\n")

                # å¤–é”®ä¿¡æ¯
                if table['foreign_keys']:
                    f.write("#### å¤–é”®\n\n")
                    for fk in table['foreign_keys']:
                        f.write(f"- **{fk['column']}** â†’ {fk['referenced_table']}.{fk['referenced_column']}\n")
                    f.write("\n")

                f.write("---\n\n")

        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” CoreBank æ•°æ®åº“ç»“æ„å®Œæ•´æå–å·¥å…·")
    print("=" * 50)

    # åˆ›å»ºåˆ†æå™¨
    analyzer = DatabaseStructureAnalyzer()

    try:
        # æ‰§è¡Œå®Œæ•´åˆ†æ
        structure = analyzer.analyze_complete_structure()

        # ä¿å­˜JSONç»“æ„æ–‡ä»¶
        json_file = analyzer.save_structure_to_file(structure)

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        md_file = analyzer.generate_markdown_report(structure)

        print("\n" + "=" * 50)
        print("âœ… åˆ†æå®Œæˆï¼")
        print(f"ğŸ“„ JSONç»“æ„æ–‡ä»¶: {json_file}")
        print(f"ğŸ“‹ MarkdownæŠ¥å‘Š: {md_file}")
        print("=" * 50)

        # æ˜¾ç¤ºç®€è¦ç»Ÿè®¡
        stats = structure['statistics']
        print(f"\nğŸ“Š æ•°æ®åº“æ¦‚è§ˆ:")
        print(f"   æ€»è¡¨æ•°: {stats['total_tables']}")
        print(f"   æ€»è¡Œæ•°: {stats['total_rows']}")
        print(f"   å¤–é”®å…³ç³»: {len(structure['foreign_key_relationships'])}")

        print(f"\nğŸ“‹ è¡¨åˆ—è¡¨:")
        for table_stat in stats['table_statistics']:
            print(f"   - {table_stat['table_name']}: {table_stat['row_count']} è¡Œ")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

    def get_all_foreign_key_relationships(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å¤–é”®å…³ç³»"""
        print("ğŸ”— åˆ†æå¤–é”®å…³ç³»...")

        query = """
        SELECT
            tc.table_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name,
            tc.constraint_name
        FROM information_schema.table_constraints AS tc
        JOIN information_schema.key_column_usage AS kcu
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage AS ccu
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY'
        ORDER BY tc.table_name, kcu.column_name;
        """

        result = self.execute_sql(query)
        relationships = []

        lines = result.split('\n')
        data_started = False

        for line in lines:
            line = line.strip()
            if '|' in line and data_started:
                parts = [p.strip() for p in line.split('|')]
                if len(parts) >= 5:
                    relationships.append({
                        "from_table": parts[0],
                        "from_column": parts[1],
                        "to_table": parts[2],
                        "to_column": parts[3],
                        "constraint_name": parts[4]
                    })
            elif 'table_name' in line:
                data_started = True

        return relationships

    def get_database_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“ˆ è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯...")

        tables = self.get_all_tables()
        total_rows = 0
        table_stats = []

        for table in tables:
            row_count = self.get_table_row_count(table)
            table_size = self.get_table_size(table)
            total_rows += row_count

            table_stats.append({
                "table_name": table,
                "row_count": row_count,
                "size": table_size
            })

        return {
            "total_tables": len(tables),
            "total_rows": total_rows,
            "table_statistics": table_stats
        }

    def analyze_complete_structure(self) -> Dict[str, Any]:
        """å®Œæ•´åˆ†ææ•°æ®åº“ç»“æ„"""
        print("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®åº“ç»“æ„åˆ†æ...")
        print("=" * 60)

        # è·å–åŸºæœ¬ä¿¡æ¯
        db_info = self.get_database_info()
        print(f"æ•°æ®åº“: {db_info['database_name']}")
        print(f"ç‰ˆæœ¬: {db_info['version']}")
        print(f"å¤§å°: {db_info['size']}")

        # è·å–æ‰€æœ‰è¡¨
        tables = self.get_all_tables()
        print(f"è¡¨æ•°é‡: {len(tables)}")

        # åˆ†ææ¯ä¸ªè¡¨
        table_structures = []
        for table in tables:
            structure = self.get_table_structure(table)
            table_structures.append(structure)

        # è·å–å¤–é”®å…³ç³»
        foreign_key_relationships = self.get_all_foreign_key_relationships()

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        statistics = self.get_database_statistics()

        # ç»„è£…å®Œæ•´ç»“æ„
        complete_structure = {
            "database_info": db_info,
            "tables": table_structures,
            "foreign_key_relationships": foreign_key_relationships,
            "statistics": statistics
        }

        return complete_structure

    def save_structure_to_file(self, structure: Dict[str, Any], filename: Optional[str] = None) -> str:
        """ä¿å­˜ç»“æ„åˆ°JSONæ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"database_structure_{timestamp}.json"

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(structure, f, ensure_ascii=False, indent=2, default=str)

        print(f"âœ… æ•°æ®åº“ç»“æ„å·²ä¿å­˜åˆ°: {filename}")
        return filename

    def generate_markdown_report(self, structure: Dict[str, Any], filename: Optional[str] = None) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"database_analysis_report_{timestamp}.md"

        with open(filename, 'w', encoding='utf-8') as f:
            f.write("# CoreBank æ•°æ®åº“ç»“æ„åˆ†ææŠ¥å‘Š\n\n")

            # åŸºæœ¬ä¿¡æ¯
            db_info = structure['database_info']
            f.write("## ğŸ“Š æ•°æ®åº“åŸºæœ¬ä¿¡æ¯\n\n")
            f.write(f"- **æ•°æ®åº“å**: {db_info['database_name']}\n")
            f.write(f"- **ç‰ˆæœ¬**: {db_info['version']}\n")
            f.write(f"- **å¤§å°**: {db_info['size']}\n")
            f.write(f"- **è¡¨æ•°é‡**: {db_info['table_count']}\n")
            f.write(f"- **åˆ†ææ—¶é—´**: {db_info['analysis_time']}\n\n")

            # ç»Ÿè®¡ä¿¡æ¯
            stats = structure['statistics']
            f.write("## ğŸ“ˆ æ•°æ®ç»Ÿè®¡\n\n")
            f.write("| è¡¨å | è¡Œæ•° | å¤§å° |\n")
            f.write("|------|------|------|\n")
            for table_stat in stats['table_statistics']:
                f.write(f"| {table_stat['table_name']} | {table_stat['row_count']} | {table_stat['size']} |\n")
            f.write(f"\n**æ€»è®¡**: {stats['total_tables']} ä¸ªè¡¨ï¼Œ{stats['total_rows']} è¡Œæ•°æ®\n\n")

            # è¡¨ç»“æ„è¯¦æƒ…
            f.write("## ğŸ—ï¸ è¡¨ç»“æ„è¯¦æƒ…\n\n")
            for table in structure['tables']:
                f.write(f"### {table['table_name']}\n\n")

                # åˆ—ä¿¡æ¯
                f.write("#### åˆ—ä¿¡æ¯\n\n")
                f.write("| åˆ—å | æ•°æ®ç±»å‹ | å¯ç©º | é»˜è®¤å€¼ | è¯´æ˜ |\n")
                f.write("|------|----------|------|--------|------|\n")
                for col in table['columns']:
                    nullable = "æ˜¯" if col['nullable'] else "å¦"
                    default = col['default'] if col['default'] else "-"
                    f.write(f"| {col['name']} | {col['data_type']} | {nullable} | {default} | - |\n")
                f.write("\n")

                # çº¦æŸä¿¡æ¯
                if table['constraints']:
                    f.write("#### çº¦æŸ\n\n")
                    for constraint in table['constraints']:
                        f.write(f"- **{constraint['name']}** ({constraint['type']})")
                        if constraint['column']:
                            f.write(f": {constraint['column']}")
                        f.write("\n")
                    f.write("\n")

                # ç´¢å¼•ä¿¡æ¯
                if table['indexes']:
                    f.write("#### ç´¢å¼•\n\n")
                    for index in table['indexes']:
                        f.write(f"- **{index['name']}**: {index['definition']}\n")
                    f.write("\n")

                # å¤–é”®ä¿¡æ¯
                if table['foreign_keys']:
                    f.write("#### å¤–é”®\n\n")
                    for fk in table['foreign_keys']:
                        f.write(f"- **{fk['column']}** â†’ {fk['referenced_table']}.{fk['referenced_column']}\n")
                    f.write("\n")

                f.write(f"**è¡Œæ•°**: {table['row_count']} | **å¤§å°**: {table['table_size']}\n\n")
                f.write("---\n\n")

            # å¤–é”®å…³ç³»å›¾
            f.write("## ğŸ”— å¤–é”®å…³ç³»\n\n")
            for rel in structure['foreign_key_relationships']:
                f.write(f"- {rel['from_table']}.{rel['from_column']} â†’ {rel['to_table']}.{rel['to_column']}\n")

        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename
